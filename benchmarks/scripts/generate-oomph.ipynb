{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD        : /home/biddisco/src/ghex/extern/oomph/benchmarks/scripts \n",
      "Scriptpath : /tmp/ipykernel_103958 \n",
      "Hostname   : oryx2\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import math\n",
    "import numpy as np\n",
    "import inspect\n",
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "from IPython.display import Image, display, HTML\n",
    "import importlib\n",
    "import socket\n",
    "import argparse\n",
    "\n",
    "# working dir\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# hostname + cleanup login node 'daint101' etc\n",
    "hostname = socket.gethostname()\n",
    "if hostname.startswith('daint'):\n",
    "    hostname = 'daint'\n",
    "if hostname.startswith('uan'):\n",
    "    hostname = 'eiger'\n",
    "\n",
    "# name of this script\n",
    "scriptname = inspect.getframeinfo(inspect.currentframe()).filename\n",
    "scriptpath = os.path.dirname(os.path.abspath(scriptname))\n",
    "\n",
    "# summary\n",
    "print(f'CWD        : {cwd} \\nScriptpath : {scriptpath} \\nHostname   : {hostname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook generate-oomph.ipynb to script\n",
      "[NbConvertApp] Writing 11796 bytes to generate-oomph.py\n"
     ]
    }
   ],
   "source": [
    "def is_notebook():\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        elif shell == 'TerminalInteractiveShell':\n",
    "            return False  # Terminal running IPython\n",
    "        else:\n",
    "            return False  # Other type (?)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "\n",
    "if is_notebook():\n",
    "    # this makes the notebook wider on a larger screen using %x of the display\n",
    "    display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "    # save this notebook as a raw python file as well please\n",
    "    get_ipython().system('jupyter nbconvert --to script generate-oomph.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Command line params\n",
    "# ------------------------------------------------------------------\n",
    "def get_command_line_args(notebook_args=None):\n",
    "    parser = argparse.ArgumentParser(description='Generator for oomph benchmarks')\n",
    "    parser.add_argument('-d', '--dir', default=cwd, action='store', help='base directory to generate job scripts in')\n",
    "    parser.add_argument('-t', '--type', default='normal', action='store', help='normal, timed or native for different test types')\n",
    "    parser.add_argument('-m', '--timeout', default=120, action='store', help='executable timeout period')\n",
    "    if is_notebook():\n",
    "        parser.add_argument('-f', help='seems to be defaulted by jupyter')\n",
    "        return parser.parse_args(notebook_args)\n",
    "    return parser.parse_args()\n",
    "\n",
    "notebook_args = '--type=native --dir /home/biddisco/benchmarking-results/test'.split()\n",
    "if is_notebook():\n",
    "    args = get_command_line_args(notebook_args)\n",
    "else:\n",
    "    args = get_command_line_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_executable(path):\n",
    "    mode = os.stat(path).st_mode\n",
    "    mode |= (mode & 0o444) >> 2    # copy R bits to X\n",
    "    os.chmod(path, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating scripts in /home/biddisco/benchmarking-results/test\n"
     ]
    }
   ],
   "source": [
    "# strings with @xxx@ will be substituted by cmake\n",
    "binary_dir = \"@BIN_DIR@\"\n",
    "\n",
    "if args.dir:\n",
    "    run_dir = args.dir\n",
    "else:\n",
    "    run_dir = \"@RUN_DIR@\"\n",
    "\n",
    "print(f'Generating scripts in {run_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cscs = {}\n",
    "\n",
    "# jb laptop\n",
    "cscs[\"oryx2\"] = {\n",
    "  \"Machine\":\"system76\",\n",
    "  \"Cores\": 8,\n",
    "  \"Threads per core\": 2,\n",
    "  \"Allowed rpns\": [1, 2],\n",
    "  \"Thread_array\": [1,2,4],\n",
    "  \"Sleeptime\":0,\n",
    "  \"Launch\": \"pushd {job_path} && source {job_file} && popd\",\n",
    "  \"Run command\": \"mpiexec -n {total_ranks} --oversubscribe timeout {timeout} \",\n",
    "  \"Batch preamble\": \"\"\"\n",
    "#!/bin/bash -l\n",
    "\n",
    "# Env\n",
    "#export OMP_NUM_THREADS={threads}\n",
    "#export GOMP_CPU_AFFINITY=0-{threadsm1}\n",
    "\n",
    "# Commands\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "# daint mc nodes config\n",
    "cscs[\"daint\"] = {\n",
    "  \"Machine\":\"daint\",\n",
    "  \"Cores\": 128,\n",
    "  \"Threads per core\": 2,\n",
    "  \"Allowed rpns\": [1],\n",
    "  \"Thread_array\": [1,2,4,8,16],\n",
    "  \"Sleeptime\":0.25,\n",
    "  \"Launch\": \"sbatch --chdir={job_path} {job_file}\",\n",
    "  \"Run command\": \"srun --cpu-bind=cores --unbuffered --ntasks {total_ranks} --cpus-per-task {threads_per_rank} timeout {timeout} \",\n",
    "  \"Batch preamble\": \"\"\"\n",
    "#!/bin/bash -l\n",
    "#SBATCH --job-name={run_name}_{transport}_{nodes}_{threads}_{inflight}_{size}\n",
    "#SBATCH --time={time_min}\n",
    "#SBATCH --nodes={nodes}\n",
    "#SBATCH --partition=normal\n",
    "#SBATCH --account=csstaff\n",
    "#SBATCH --constraint=mc\n",
    "#SBATCH --output=output.txt\n",
    "#SBATCH --error=error.txt\n",
    "\n",
    "module swap craype/2.7.10 craype/2.7.15\n",
    "\n",
    "# alternatives : srun --cpu-bind v,mask_cpu:0xffff\n",
    "# export GOMP_CPU_AFFINITY=0-{threadsm1}\n",
    "\n",
    "# Old Env vars that might be useful\n",
    "# export MPICH_MAX_THREAD_SAFETY=multiple\n",
    "# export OMP_NUM_THREADS={threads}\n",
    "# export MKL_NUM_THREADS={threads}\n",
    "# export MPICH_GNI_NDREG_ENTRIES=1024\n",
    "\n",
    "# Debug\n",
    "module list &> modules.txt\n",
    "printenv > env.txt\n",
    "\n",
    "# Commands\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "cscs['eiger'] = cscs['daint']\n",
    "cscs['eiger']['Machine'] = 'eiger'\n",
    "cscs['eiger']['Cores'] = 64\n",
    "cscs['eiger']['Thread_array'] = [1,2,4,8,16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Generate Job script preamble\n",
    "#\n",
    "def init_job_text(system, run_name, time_min, transport, nodes, threads, inflight, size):\n",
    "    return system[\"Batch preamble\"].format(run_name=run_name,\n",
    "                                           time_min=time_min,\n",
    "                                           transport=transport,\n",
    "                                           nodes=nodes,\n",
    "                                           threads=threads,\n",
    "                                           threadsm1=(threads-1),\n",
    "                                           inflight=inflight,\n",
    "                                           size=size).strip()\n",
    "#\n",
    "# create a directory name from params\n",
    "#\n",
    "def make_job_directory(fdir,name, transport, nodes, threads, inflight, size):\n",
    "    return f'{fdir}/{name}_{transport}_{nodes}_{threads}_{inflight}_{size}'\n",
    "\n",
    "#\n",
    "# create the launch command-line\n",
    "#\n",
    "def run_command(system, total_ranks, cpus_per_rank, timeout):\n",
    "    return system[\"Run command\"].format(total_ranks=total_ranks, cpus_per_rank=cpus_per_rank, threads_per_rank=cpus_per_rank, timeout=timeout)\n",
    "\n",
    "#\n",
    "# create dir + write final script for sbatch/shell or other job launcher\n",
    "#\n",
    "def write_job_file(system, launch_file, job_dir, job_text, suffix=''):\n",
    "    job_path = os.path.expanduser(job_dir)\n",
    "    os.makedirs(job_path, exist_ok=True)\n",
    "    job_file = f\"{job_path}/job_{suffix}.sh\"\n",
    "    print(f\"Generating : {job_path} : {job_file}\")\n",
    "\n",
    "    with open(job_file, \"w\") as f:\n",
    "        f.write(job_text)\n",
    "        make_executable(job_file)\n",
    "\n",
    "    launchstring  = system[\"Launch\"].format(job_path=job_path,job_file=job_file) + '\\n'\n",
    "    launchstring += 'sleep ' + str(system['Sleeptime']) + '\\n'\n",
    "    launch_file.write(launchstring)\n",
    "\n",
    "#\n",
    "# generate a string that decorates and launches a single instance of the test\n",
    "#\n",
    "def execution_string(env, launch_cmd, prog_cmd, output_redirect):\n",
    "    full_command = f\"{env} {launch_cmd} {prog_cmd}\".strip()\n",
    "    command_prologue  = f'printf \"\\\\n'\n",
    "    command_prologue += f'# ----- Executing \\\\n'\n",
    "    command_prologue += f'{full_command}    \\\\n'\n",
    "    command_prologue += f'# --------------- \\\\n\" >> {output_redirect}'\n",
    "    command_epilogue  = f'printf \"\\\\n'\n",
    "    command_epilogue += f'# ----- Finished  \\\\n\\\\n\" >> {output_redirect}'\n",
    "    return '\\n' + command_prologue + '\\n' + full_command + ' >> ' + output_redirect + '\\n' + command_epilogue + '\\n'\n",
    "\n",
    "#\n",
    "# generate application specific commmands/flags/options that go into the job script\n",
    "#\n",
    "def oomph_original(system, bin_dir, timeout, transport, progs, nodes, threads, msg, size, inflight, env):\n",
    "    total_ranks = 2\n",
    "    whole_cmd = ''\n",
    "    suffix = ''\n",
    "\n",
    "    # transport layers use '_libfabric', '_ucx', '_mpi', etc\n",
    "    if args.type!='native':\n",
    "        suffix = f'_{transport}'\n",
    "\n",
    "    # timed version uses seconds instead of messages/iterations\n",
    "    if args.type=='timed':\n",
    "        msg = 30\n",
    "\n",
    "    # always remember to add a space to the end of each env var for concatenation of many of them\n",
    "    if threads==1:\n",
    "        env +=  'MPICH_MAX_THREAD_SAFETY=single '\n",
    "    else:\n",
    "        env +=  'MPICH_MAX_THREAD_SAFETY=multiple '\n",
    "        env += f'OMP_NUM_THREADS={threads} '\n",
    "        # env += f'GOMP_CPU_AFFINITY=0-{threads} '\n",
    "\n",
    "    for prog in progs:\n",
    "        if threads>1:\n",
    "            if args.type=='normal' or args.type=='timed':\n",
    "                prog = prog + '_mt'\n",
    "\n",
    "        if transport=='native' and threads==1:\n",
    "            prog = prog.replace('_mt_','_')\n",
    "\n",
    "        # generate the name of the output file we redirect output to\n",
    "        outfile = f'{prog}_N{nodes}_T{threads}_I{msg}_S{size}_F{inflight}.out'\n",
    "\n",
    "        # generate the program commmand with all command line params needed by program\n",
    "        prog_cmd = f\"{bin_dir}/{prog}{suffix} {msg} {size} {inflight}\"\n",
    "\n",
    "        # get the system launch command (mpiexec, srun, etc) with options/params\n",
    "        launch_cmd = run_command(system, total_ranks, threads, timeout)\n",
    "\n",
    "        if transport=='libfabric':\n",
    "            env2 = env + 'LIBFABRIC_POLL_SIZE=32 '\n",
    "            #for ep in ['single', 'multiple', 'scalable', 'threadlocal']:\n",
    "            for ep in ['threadlocal']:\n",
    "                whole_cmd += execution_string(env2 + f\"LIBFABRIC_ENDPOINT_TYPE={ep} \", launch_cmd, prog_cmd, outfile)\n",
    "            if False: # add option to enable this?\n",
    "                whole_cmd += execution_string(env2 + f\"LIBFABRIC_ENDPOINT_TYPE={ep} \" + f\"LIBFABRIC_AUTO_PROGRESS=1 \", launch_cmd, prog_cmd, outfile)\n",
    "        else:\n",
    "            whole_cmd += execution_string(env, launch_cmd, prog_cmd, outfile)\n",
    "\n",
    "    return whole_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = cscs[hostname]\n",
    "#\n",
    "job_name       = 'oomph'\n",
    "timeout        = args.timeout\n",
    "time_min       = 2000*60 # total time estimate\n",
    "timestr        = time.strftime('%H:%M:%S', time.gmtime(time_min))\n",
    "ranks_per_node = 1\n",
    "nodes_arr = [2]\n",
    "thrd_arr  = system['Thread_array']\n",
    "size_arr  = [1,10,100,1000,10000,100000,1000000]\n",
    "nmsg_lut  = {1:500000,\n",
    "             10:500000,\n",
    "             100:500000,\n",
    "             1000:500000,\n",
    "             5000:250000,\n",
    "             10000:250000,\n",
    "             50000:250000,\n",
    "             100000:250000,\n",
    "             200000:250000,\n",
    "             500000:100000,\n",
    "             1000000:50000,\n",
    "             2000000:25000}\n",
    "\n",
    "flight_arr = [1,10,100]\n",
    "\n",
    "if args.type=='normal':\n",
    "    trans_arr = ['libfabric', 'mpi']\n",
    "    prog_arr  = [\n",
    "        #\"bench_p2p_bi_cb_avail\",\n",
    "        #\"bench_p2p_bi_cb_wait\",\n",
    "        \"bench_p2p_bi_ft_avail\",\n",
    "        #\"bench_p2p_bi_ft_wait\"\n",
    "    ]\n",
    "\n",
    "if args.type=='timed':\n",
    "    trans_arr = ['libfabric', 'mpi']\n",
    "    prog_arr  = ['bench_p2p_pp_ft_avail']\n",
    "\n",
    "if args.type=='native':\n",
    "    trans_arr = ['native']\n",
    "    prog_arr  = [\n",
    "        #\"mpi_p2p_bi_avail_mt_test\", \"mpi_p2p_bi_avail_mt_testany\",\n",
    "        #\"mpi_p2p_bi_wait_mt_wait\",\n",
    "        \"mpi_p2p_bi_wait_mt_waitall\"\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncommment the following line to perform the job creation\n",
      "Generating : /home/biddisco/benchmarking-results/test/oomph_all_2_1_1_1 : /home/biddisco/benchmarking-results/test/oomph_all_2_1_1_1/job_.sh\n",
      "Combinations 63 est-time 504 minutes\n"
     ]
    }
   ],
   "source": [
    "combos = 0\n",
    "\n",
    "if run_dir.startswith('@'):\n",
    "    print(f'Skipping creation of job launch file for {run_dir}')\n",
    "else:\n",
    "    job_launch = f\"{run_dir}/launch.sh\"\n",
    "    job_launch_file = open(job_launch, \"w\")\n",
    "    #\n",
    "    job_launch_file.write(\"#!/bin/bash -l\\n\")\n",
    "\n",
    "# create the output directory for each job\n",
    "job_dir = make_job_directory(run_dir, 'oomph', \"all\", 2, 1, 1, 1)\n",
    "\n",
    "# first part of boiler plate job script\n",
    "job_text = init_job_text(system, job_name, timestr, \"all\", 2, 16, 1, 1)\n",
    "\n",
    "# generate all combinations in one monster loop\n",
    "for nodes, transport, threads, size, inflight in product(nodes_arr, trans_arr, thrd_arr, size_arr, flight_arr):\n",
    "\n",
    "    env = \"\"\n",
    "    msg = nmsg_lut[size]\n",
    "\n",
    "    # create the output directory for each job\n",
    "    #job_dir = make_job_directory(run_dir, 'oomph', transport, nodes, threads, inflight, size)\n",
    "\n",
    "    # first part of boiler plate job script\n",
    "    #job_text = init_job_text(system, job_name, timestr, transport, nodes, threads, inflight, size)\n",
    "\n",
    "    env = 'MPICH_GNI_NDREG_ENTRIES=1024 '\n",
    "\n",
    "    # application specific part of job script\n",
    "    job_text += oomph_original(\n",
    "        system,\n",
    "        binary_dir,\n",
    "        timeout,\n",
    "        transport,\n",
    "        prog_arr,\n",
    "        nodes,\n",
    "        threads,\n",
    "        msg,\n",
    "        size,\n",
    "        inflight,\n",
    "        env\n",
    "    )\n",
    "    # debugging\n",
    "    # print(job_dir, '\\n', job_text, '\\n\\n\\n\\n')\n",
    "\n",
    "    combos += 1\n",
    "\n",
    "    if combos==1:\n",
    "        print('Uncommment the following line to perform the job creation')\n",
    "\n",
    "write_job_file(system, job_launch_file, job_dir, job_text)\n",
    "\n",
    "make_executable(job_launch)\n",
    "print('Combinations', combos, 'est-time', combos*4*2,'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
